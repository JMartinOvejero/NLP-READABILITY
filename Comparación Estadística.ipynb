{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def bootstrap_significance_testing(y_true, y_predA, y_predB, metric, n=int(1e5)):\n",
    "   \n",
    "    v1 = metric(y_true, y_predA)\n",
    "    v2 = metric(y_true, y_predB)\n",
    "    d = 2 * (v1 - v2)\n",
    "\n",
    "    s = 0\n",
    "\n",
    "    l = len(y_true)\n",
    "    for i in range(n):\n",
    "        idx = np.random.choice(l, l)\n",
    "\n",
    "        v1i = metric(y_true[idx], y_predA[idx])\n",
    "        v2i = metric(y_true[idx], y_predB[idx])\n",
    "        di = v1i - v2i\n",
    "\n",
    "        if di > d:\n",
    "            s += 1\n",
    "\n",
    "    return s / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "metric = lambda predA, predB: abs(spearmanr(predA, predB)[0])\n",
    "n = int(1e4)\n",
    "\n",
    "def flesch(df):\n",
    "  \n",
    "    \n",
    "    # Flesch \n",
    "    df[\"Flesch\"] = 206.835 - 1.015 * df[\"Avg_words_per_sentence\"] - 84.6 * df[\"Avg_syllables_per_word\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# DALE-CHALL\n",
    "\n",
    "\n",
    "def dale_chall(df):\n",
    "   \n",
    "\n",
    "\n",
    "    # Dale-Chall \n",
    "    df[\"Dale_Chall\"] = 0.1579 * (df[\"Difficult_word_percent\"] * 100) + 0.0496 * df[\"Avg_words_per_sentence\"]\n",
    "    \n",
    "    \n",
    "    df.loc[df[\"Difficult_word_percent\"] > 0.05, \"Dale_Chall\"] += 3.6365\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "# GUNNING FOG\n",
    "\n",
    "\n",
    "def gunning_fog(df):\n",
    "    \n",
    "\n",
    "    df[\"Gunning_fog\"] = 0.4 * (df[\"Avg_words_per_sentence\"] + 100 * df[\"Complex_word_percent\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv(\"weebit_train_with_features.csv\", index_col=0)\n",
    "X_test = pd.read_csv(\"weebit_test_with_features.csv\", index_col=0)\n",
    "\n",
    "# get Y\n",
    "y_train = X_train[\"Level\"]\n",
    "y_test = X_test[\"Level\"]\n",
    "\n",
    "# remove Y and Text columns \n",
    "X_train.drop(columns=['Text', 'Level'], inplace=True)\n",
    "X_test.drop(columns=['Text', 'Level'], inplace=True)\n",
    "\n",
    "# whole set\n",
    "X = pd.concat([X_train, X_test]).reset_index(drop=True)\n",
    "y = pd.concat([y_train, y_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = flesch(X)\n",
    "X = dale_chall(X)\n",
    "X = gunning_fog(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38278239601713643"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y, X[\"Dale_Chall\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.359949119283807"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y, X[\"Flesch\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p-value: 0.9025\n"
     ]
    }
   ],
   "source": [
    "p_value = bootstrap_significance_testing(y, X['Flesch'], X['Dale_Chall'], metric, n=n)\n",
    "print(\"Estimated p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.359949119283807"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y, X[\"Flesch\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3730664167001242"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y, X[\"Gunning_fog\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p-value: 0.1294\n"
     ]
    }
   ],
   "source": [
    "p_value = bootstrap_significance_testing(y, X['Gunning_fog'], X['Flesch'], metric, n=n)\n",
    "print(\"Estimated p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38278239601713643"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y, X[\"Dale_Chall\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3730664167001242"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y, X[\"Gunning_fog\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p-value: 0.6984\n"
     ]
    }
   ],
   "source": [
    "p_value = bootstrap_significance_testing(y, X['Gunning_fog'], X['Dale_Chall'], metric, n=n)\n",
    "print(\"Estimated p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, r2_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    \n",
    "    print(\"================================================\")\n",
    "    print(\"Spearman's correlation coef: \" + str(spearmanr(y_true, y_pred)[0]))\n",
    "    print(\"================================================\")\n",
    "    \n",
    "    print(\"-----------\")\n",
    "    print(\"R^2 = \" + str(r2_score(y_true, y_pred)))\n",
    "    print(\"R = \" + str(np.sqrt(r2_score(y_true, y_pred))))\n",
    "    print(\"-----------\")\n",
    "    \n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def grid_search_cv_for_ensembles(model, max_depth_values, n_estimators_values, X, y, scoring_function, k=5, verbose=0):\n",
    "   \n",
    "    \n",
    "    best_score = 0.0\n",
    "    best_n_estimators = 1\n",
    "    best_max_depth = 1\n",
    "    \n",
    "    for max_depth in max_depth_values: \n",
    "        for n_estimators in n_estimators_values:\n",
    "            \n",
    "            kf = KFold(n_splits=k, random_state=None, shuffle=True)\n",
    "\n",
    "            fold = 1\n",
    "            scores = []\n",
    "            for train_index, test_index in kf.split(X):\n",
    "\n",
    "                # get train and test set for the i-th fold\n",
    "                X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                # train and predict\n",
    "                model.set_hyperparams(max_depth, n_estimators)\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                scores.append(scoring_function(y_test, y_pred))\n",
    "\n",
    "                fold += 1\n",
    "              \n",
    "            score = np.mean(scores)\n",
    "            \n",
    "            if verbose > 0:\n",
    "                print(\"score=\" + str(score) + \" | max_depth=\" + str(max_depth) + \" n_estimators=\" + str(n_estimators))\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_n_estimators = n_estimators\n",
    "                best_max_depth = max_depth\n",
    "\n",
    "    return best_max_depth, best_n_estimators\n",
    "\n",
    "\n",
    "def find_best_C(model, c_values, X, y, scoring_function, k=5, verbose=0):\n",
    "    \n",
    "    best_score = 0.0\n",
    "    best_c = 1.0\n",
    "    \n",
    "    for c in c_values: \n",
    "            \n",
    "        kf = KFold(n_splits=k, random_state=None, shuffle=True)\n",
    "\n",
    "        fold = 1\n",
    "        scores = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "\n",
    "            # get train and test set for the i-th fold\n",
    "            X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # train and predict\n",
    "            model.set_hyperparams('linear', c)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            scores.append(scoring_function(y_test, y_pred))\n",
    "\n",
    "            fold += 1\n",
    "\n",
    "        score = np.mean(scores)\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(\"score=\" + str(score) + \" | C=\" + str(c))\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_c = c\n",
    "\n",
    "    return best_c\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def discretize(y_pred):\n",
    "    \n",
    "    \n",
    "    for i in range(len(y_pred)):    \n",
    "        if y_pred[i] < 0.5:\n",
    "            y_pred[i] = 0.0\n",
    "        elif y_pred[i] < 1.5:\n",
    "            y_pred[i] = 1.0\n",
    "        elif y_pred[i] < 2.5:\n",
    "            y_pred[i] = 2.0\n",
    "        elif y_pred[i] < 3.5:\n",
    "            y_pred[i] = 3.0\n",
    "        else:\n",
    "            y_pred[i] = 4.0\n",
    "            \n",
    "    return y_pred\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RandomForest():\n",
    "  \n",
    "    \n",
    "    def __init__(self, max_depth=20, n_estimators=100, save_model=False, use_saved_model=False, model_path='./models/saved_models/rf.pickle'):\n",
    "        self.model_path = model_path\n",
    "        self.save_model = save_model\n",
    "        \n",
    "        if use_saved_model:\n",
    "            with open(self.model_path, 'rb') as file:\n",
    "                self.model = pickle.load(file)\n",
    "        else:\n",
    "            self.model = RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators)    \n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        if self.save_model:\n",
    "            with open(self.model_path, 'wb') as handle:\n",
    "                pickle.dump(self.model, handle)\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return discretize(self.model.predict(X_test))\n",
    "    \n",
    "    \n",
    "    def set_hyperparams(self, max_depth, n_estimators):\n",
    "        \n",
    "        self.model = RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators)  \n",
    "        \n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "class MultilayerPerceptron():\n",
    "  \n",
    "    \n",
    "    def __init__(self, input_dim=None, verbose=0, save_model=False, use_saved_model=False, model_path='./models/saved_models/mlp.h5'):\n",
    "        self.model_path = model_path\n",
    "        self.save_model = save_model\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.verbose = verbose\n",
    "\n",
    "        \n",
    "        if use_saved_model:\n",
    "            self.model = load_model(model_path)\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = self._make_model()\n",
    "        \n",
    "        y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=5)\n",
    "        \n",
    "        self.model.fit(\n",
    "            X_train, y_train_cat,\n",
    "            epochs=150,\n",
    "            batch_size=64,\n",
    "            verbose=self.verbose)\n",
    "        \n",
    "        if self.save_model:\n",
    "            self.model.save(self.model_path)\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test): \n",
    "        y_pred_cat = self.model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_cat, axis=1)\n",
    "        \n",
    "        return discretize(y_pred)\n",
    "    \n",
    "    \n",
    "    def _make_model(self):\n",
    "        \n",
    "        # architecture\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, activation='relu', input_dim=self.input_dim))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(5, activation='linear'))\n",
    "        \n",
    "        # opitimizer\n",
    "        adam = tf.keras.optimizers.Adam(lr=0.001)\n",
    "        \n",
    "        model.compile(optimizer=adam,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "from xgboost import XGBRegressor\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class XGBoost():\n",
    "    \n",
    "    \n",
    "    def __init__(self, max_depth=30, n_estimators=200, save_model=False, use_saved_model=False, model_path='./models/saved_models/xgboost.pickle'):\n",
    "        self.model_path = model_path\n",
    "        self.save_model = save_model\n",
    "        \n",
    "        if use_saved_model:\n",
    "            with open(self.model_path, 'rb') as file:\n",
    "                self.model = pickle.load(file)\n",
    "        else:\n",
    "            self.model = xgboost = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, objective=\"reg:squarederror\")  \n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        if self.save_model:\n",
    "            with open(self.model_path, 'wb') as handle:\n",
    "                pickle.dump(self.model, handle)\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return discretize(self.model.predict(X_test))\n",
    "    \n",
    "    \n",
    "    def set_hyperparams(self, max_depth, n_estimators):\n",
    "       \n",
    "        \n",
    "        self.model = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, objective=\"reg:squarederror\")  \n",
    "        \n",
    "from sklearn.svm import SVR\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SupportVectorMachine():\n",
    " \n",
    "    \n",
    "    def __init__(self, kernel='linear', C=10.0, save_model=False, use_saved_model=False, model_path='./models/saved_models/svm.pickle'):\n",
    "        self.model_path = model_path\n",
    "        self.save_model = save_model\n",
    "        \n",
    "        if use_saved_model:\n",
    "            with open(self.model_path, 'rb') as file:\n",
    "                self.model = pickle.load(file)\n",
    "        else:\n",
    "            self.model = SVR(kernel=kernel, C=C)\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        if self.save_model:\n",
    "            with open(self.model_path, 'wb') as handle:\n",
    "                pickle.dump(self.model, handle)\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return discretize(self.model.predict(X_test))\n",
    "    \n",
    "    \n",
    "    def set_hyperparams(self, kernel, c):\n",
    "       \n",
    "        \n",
    "        self.model = SVR(kernel=kernel, C=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForest(use_saved_model=True, model_path='rf.pickle')\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "xgboost = XGBoost(use_saved_model=True, model_path='xgboost.pickle')\n",
    "y_pred_xgboost = xgboost.predict(X_test)\n",
    "\n",
    "svm = SupportVectorMachine(use_saved_model=True, model_path='svm.pickle')\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "mlp = MultilayerPerceptron(input_dim=X_train.shape[1], use_saved_model=True, verbose=0, model_path='mlp.h5')\n",
    "y_pred_mlp = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p-value: 0.1374\n"
     ]
    }
   ],
   "source": [
    "p_value = bootstrap_significance_testing(y_test, y_pred_mlp, y_pred_xgboost, metric, n=n)\n",
    "print(\"Estimated p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p-value: 0.4633\n"
     ]
    }
   ],
   "source": [
    "p_value = bootstrap_significance_testing(y_test, y_pred_mlp, y_pred_svm, metric, n=n)\n",
    "print(\"Estimated p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p-value: 0.8933\n"
     ]
    }
   ],
   "source": [
    "p_value = bootstrap_significance_testing(y_test, y_pred_rf, y_pred_xgboost, metric, n=n)\n",
    "print(\"Estimated p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p-value: 0.9817\n"
     ]
    }
   ],
   "source": [
    "p_value = bootstrap_significance_testing(y_test, y_pred_rf, y_pred_svm, metric, n=n)\n",
    "print(\"Estimated p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p-value: 0.0222\n"
     ]
    }
   ],
   "source": [
    "p_value = bootstrap_significance_testing(y_test, y_pred_mlp, y_pred_rf, metric, n=n)\n",
    "print(\"Estimated p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "X_test = gunning_fog(X_test)\n",
    "p_value = bootstrap_significance_testing(y_test, y_pred_mlp, X_test['Gunning_fog'], metric, n=n)\n",
    "print(\"Estimated p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
